{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGtloqIn_qAV",
        "outputId": "4cbf568b-6cc1-4ce9-af0c-4035ff6627f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of valid captions in username2posts_train: 91285\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "from pprint import pprint\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "\n",
        "train_classification_df = pd.read_csv(\"./train-classification.csv\")\n",
        "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
        "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
        "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]\n",
        "\n",
        "train_data_path = \"./training-dataset.jsonl.gz\"\n",
        "\n",
        "username2posts_train = dict()\n",
        "username2profile_train = dict()\n",
        "username2posts_test = dict()\n",
        "username2profile_test = dict()\n",
        "\n",
        "with gzip.open(train_data_path, \"rt\", errors=\"ignore\") as fh:\n",
        "    for line in fh:\n",
        "        sample = json.loads(line)\n",
        "        profile = sample[\"profile\"]\n",
        "        username = profile[\"username\"]\n",
        "        if username in username2_category:\n",
        "            username2posts_train[username] = sample[\"posts\"]\n",
        "            username2profile_train[username] = profile\n",
        "        else:\n",
        "            username2posts_test[username] = sample[\"posts\"]\n",
        "            username2profile_test[username] = profile\n",
        "\n",
        "train_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\n",
        "test_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n",
        "\n",
        "total_captions = 0\n",
        "for posts in username2posts_train.values():\n",
        "    for post in posts:\n",
        "        if \"caption\" in post and isinstance(post[\"caption\"], str) and post[\"caption\"].strip():\n",
        "            total_captions += 1\n",
        "print(f\"Total number of valid captions in username2posts_train: {total_captions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYknvTi9N1lV",
        "outputId": "1632441f-e1a4-4b58-d675-abcbf50c2eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of valid captions in username2posts_train after filtering: 89690\n"
          ]
        }
      ],
      "source": [
        "# Filter captions with a length of at least 10 characters in username2posts_train\n",
        "for username, posts in username2posts_train.items():\n",
        "    username2posts_train[username] = [\n",
        "        post for post in posts if \"caption\" in post and isinstance(post[\"caption\"], str) and len(post[\"caption\"].strip()) >= 10\n",
        "    ]\n",
        "\n",
        "total_captions_filtered = sum(\n",
        "    len(posts) for posts in username2posts_train.values()\n",
        ")\n",
        "print(f\"Total number of valid captions in username2posts_train after filtering: {total_captions_filtered}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "weRlFtaF_qAX"
      },
      "outputs": [],
      "source": [
        "model_name = \"BAAI/bge-m3\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE0LMTLc_qAY"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(captions, batch_size=32):\n",
        "    embeddings = []\n",
        "    with tqdm(total=len(captions), desc=\"Generating Embeddings\", unit=\"caption\") as pbar:\n",
        "        for i in range(0, len(captions), batch_size):\n",
        "            batch_captions = captions[i:i+batch_size]\n",
        "            inputs = tokenizer(batch_captions, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "\n",
        "            embeddings.append(batch_embeddings)\n",
        "            pbar.update(len(batch_captions))\n",
        "\n",
        "    return np.vstack(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD39cVTE_qAY",
        "outputId": "9cb85af2-f339-4016-bdbc-9530e687cbc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Collecting Captions: 100%|██████████| 2741/2741 [00:00<00:00, 8637.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of valid captions for training: 91285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_embeddings = []\n",
        "train_labels = []\n",
        "\n",
        "all_captions = []\n",
        "all_labels = []\n",
        "\n",
        "for username, posts in tqdm(username2posts_train.items(), desc=\"Collecting Captions\"):\n",
        "    category = username2_category[username]\n",
        "    for post in posts:\n",
        "        if post and isinstance(post, dict):  # Ensure post is valid\n",
        "            caption = post.get(\"caption\", \"\")\n",
        "            if caption and isinstance(caption, str):  # Ensure caption is a string\n",
        "                caption = caption.strip()\n",
        "                if caption:\n",
        "                    all_captions.append(caption)\n",
        "                    all_labels.append(category)\n",
        "\n",
        "print(f\"Total number of valid captions for training: {len(all_captions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8fiAV0h_qAY",
        "outputId": "ba91d97d-679b-4264-e8e9-ac01dc766851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings: 100%|██████████| 89690/89690 [14:16<00:00, 104.68caption/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_embeddings: (89690, 1024)\n",
            "Shape of train_labels: (89690,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_embeddings = get_embeddings(all_captions)\n",
        "train_labels = np.array(all_labels)\n",
        "\n",
        "print(f\"Shape of train_embeddings: {train_embeddings.shape}\")\n",
        "print(f\"Shape of train_labels: {train_labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wf9LNL9V_qAZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "\n",
        "# Convert embeddings and labels to torch tensors\n",
        "X = torch.FloatTensor(train_embeddings)  # shape: [N, embedding_dim]\n",
        "y = torch.LongTensor(train_labels_encoded)  # shape: [N]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "class CaptionDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = CaptionDataset(X_train, y_train)\n",
        "val_dataset = CaptionDataset(X_val, y_val)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK314f-Asivm",
        "outputId": "0f24f3e8-b2df-4a9f-ea5d-d22b801865fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch [1/10], Train Loss: 1.2504, Val Loss: 1.0714, Learning Rate: 0.000976\n",
            "Epoch [2/10], Train Loss: 1.0995, Val Loss: 0.9886, Learning Rate: 0.000905\n",
            "Epoch [3/10], Train Loss: 1.0137, Val Loss: 0.9362, Learning Rate: 0.000794\n",
            "Epoch [4/10], Train Loss: 0.9412, Val Loss: 0.8975, Learning Rate: 0.000655\n",
            "Epoch [5/10], Train Loss: 0.8728, Val Loss: 0.8667, Learning Rate: 0.000500\n",
            "Epoch [6/10], Train Loss: 0.8135, Val Loss: 0.8477, Learning Rate: 0.000345\n",
            "Epoch [7/10], Train Loss: 0.7628, Val Loss: 0.8275, Learning Rate: 0.000206\n",
            "Epoch [8/10], Train Loss: 0.7206, Val Loss: 0.8187, Learning Rate: 0.000095\n",
            "Epoch [9/10], Train Loss: 0.6895, Val Loss: 0.8134, Learning Rate: 0.000024\n",
            "Epoch [10/10], Train Loss: 0.6729, Val Loss: 0.8175, Learning Rate: 0.000000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class AdvancedMLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, dropout_rate=0.5):\n",
        "        super(AdvancedMLPClassifier, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Dropout(p=dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.BatchNorm1d(hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_rate * 0.5)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
        "            nn.BatchNorm1d(hidden_dim // 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout_rate * 0.3)\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dim // 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = X.shape[1]  # Embedding dimension\n",
        "hidden_dim = 512\n",
        "num_classes = len(label_encoder.classes_)\n",
        "dropout_rate = 0.4\n",
        "\n",
        "model = AdvancedMLPClassifier(input_dim, hidden_dim, num_classes, dropout_rate)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Learning rate scheduler step\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_targets.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
        "          f\"Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report on validation set:\")\n",
        "print(classification_report(all_targets, all_preds, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itkemmoY1sSR",
        "outputId": "5b796a07-dd57-4468-85b8-3293ab842953"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report on validation set:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.71      0.54      0.61      1198\n",
            "       entertainment       0.66      0.56      0.61      2048\n",
            "             fashion       0.74      0.79      0.76      1937\n",
            "                food       0.80      0.86      0.83      3349\n",
            "              gaming       0.89      0.38      0.54        86\n",
            "health and lifestyle       0.65      0.75      0.69      3367\n",
            "    mom and children       0.71      0.53      0.61       995\n",
            "              sports       0.72      0.64      0.68       715\n",
            "                tech       0.74      0.82      0.78      2331\n",
            "              travel       0.83      0.73      0.77      1912\n",
            "\n",
            "            accuracy                           0.73     17938\n",
            "           macro avg       0.74      0.66      0.69     17938\n",
            "        weighted avg       0.73      0.73      0.72     17938\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and validation datasets\n",
        "full_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
        "\n",
        "combined_loader = torch.utils.data.DataLoader(full_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = AdvancedMLPClassifier(input_dim, hidden_dim, num_classes, dropout_rate)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_X, batch_y in combined_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(combined_loader)\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "          f\"Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "test_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_targets.extend(batch_y.cpu().numpy())\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_targets, all_preds, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Lx07XxFM4q",
        "outputId": "998c4e1c-9f4b-4137-b1cf-c56c5f626b21"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.2091, Learning Rate: 0.000976\n",
            "Epoch [2/10], Train Loss: 1.0434, Learning Rate: 0.000905\n",
            "Epoch [3/10], Train Loss: 0.9572, Learning Rate: 0.000794\n",
            "Epoch [4/10], Train Loss: 0.8845, Learning Rate: 0.000655\n",
            "Epoch [5/10], Train Loss: 0.8261, Learning Rate: 0.000500\n",
            "Epoch [6/10], Train Loss: 0.7666, Learning Rate: 0.000345\n",
            "Epoch [7/10], Train Loss: 0.7191, Learning Rate: 0.000206\n",
            "Epoch [8/10], Train Loss: 0.6774, Learning Rate: 0.000095\n",
            "Epoch [9/10], Train Loss: 0.6475, Learning Rate: 0.000024\n",
            "Epoch [10/10], Train Loss: 0.6296, Learning Rate: 0.000000\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.86      0.74      0.80      5988\n",
            "       entertainment       0.77      0.73      0.75     10238\n",
            "             fashion       0.85      0.88      0.86      9687\n",
            "                food       0.90      0.91      0.91     16747\n",
            "              gaming       0.93      0.55      0.69       428\n",
            "health and lifestyle       0.77      0.85      0.81     16835\n",
            "    mom and children       0.84      0.73      0.78      4974\n",
            "              sports       0.85      0.79      0.82      3575\n",
            "                tech       0.83      0.93      0.88     11657\n",
            "              travel       0.92      0.81      0.86      9561\n",
            "\n",
            "            accuracy                           0.84     89690\n",
            "           macro avg       0.85      0.79      0.82     89690\n",
            "        weighted avg       0.84      0.84      0.84     89690\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZrPRuutX_qAa"
      },
      "outputs": [],
      "source": [
        "embedding_model_name = \"BAAI/bge-m3\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
        "embedding_model = AutoModel.from_pretrained(embedding_model_name).to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUH8zlxC_qAa",
        "outputId": "54d84832-6c4a-4c3b-ba8d-98844627806f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of valid test usernames found: 1000\n"
          ]
        }
      ],
      "source": [
        "test_usernames = []\n",
        "with open(\"test-classification-round3.dat\", \"r\") as f:\n",
        "    test_usernames = [line.strip() for line in f]\n",
        "\n",
        "test_usernames = [u for u in test_usernames if u in username2posts_test or username2posts_train]\n",
        "print(f\"Number of valid test usernames found: {len(test_usernames)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcTEmY_etd0T",
        "outputId": "94b46085-d8c8-4964-cf32-584f443d986f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying users via hard voting: 100%|██████████| 1000/1000 [05:08<00:00,  3.24it/s]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import torch\n",
        "\n",
        "# Helper function to check if a caption is meaningful\n",
        "def is_meaningful_caption(caption):\n",
        "    # Remove emojis and other non-alphanumeric characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', caption)\n",
        "    # Check if there are any alphabetic characters\n",
        "    return bool(re.search(r'[a-zA-Z]', text))\n",
        "\n",
        "# Classify each post and perform hard voting for that user\n",
        "def classify_user_by_posts(username, posts, tokenizer, embedding_model, model, device, batch_size=32):\n",
        "    captions = []\n",
        "    for post in posts:\n",
        "        if \"caption\" in post and isinstance(post[\"caption\"], str):\n",
        "            caption = post[\"caption\"].strip()\n",
        "            if is_meaningful_caption(caption):  # Filter out meaningless captions\n",
        "                captions.append(caption)\n",
        "\n",
        "    if not captions:\n",
        "        return None  # No meaningful captions available for this user\n",
        "\n",
        "    # Predict category for each post\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(captions), batch_size):\n",
        "            batch_captions = captions[i:i + batch_size]\n",
        "            inputs = tokenizer(batch_captions, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "            outputs = embedding_model(**inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).to(device)\n",
        "\n",
        "            # Classify using the trained model\n",
        "            logits = model(batch_embeddings)\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    # Perform hard voting\n",
        "    category_counts = Counter(predictions)\n",
        "    majority_category = category_counts.most_common(1)[0][0]\n",
        "\n",
        "    return label_encoder.inverse_transform([majority_category])[0]\n",
        "\n",
        "# Classify each user using hard voting\n",
        "output_dict = {}\n",
        "for username in tqdm(test_usernames, desc=\"Classifying users via hard voting\"):\n",
        "    if username in username2posts_test:\n",
        "        posts = username2posts_test[username]\n",
        "    elif username in username2posts_train:\n",
        "        posts = username2posts_train[username]\n",
        "    predicted_category = classify_user_by_posts(username, posts, tokenizer, embedding_model, model, device)\n",
        "    if predicted_category:\n",
        "        output_dict[username] = predicted_category\n",
        "\n",
        "with open(\"test_predictions_round3.json\", \"w\") as json_file:\n",
        "    json.dump(output_dict, json_file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fDUxTnc__qAa"
      },
      "outputs": [],
      "source": [
        "def log_mse_like_counts(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculate the Log Mean Squared Error (Log MSE) for like counts (log(like_count + 1)).\n",
        "\n",
        "  Parameters:\n",
        "  - y_true: array-like, actual like counts\n",
        "  - y_pred: array-like, predicted like counts\n",
        "\n",
        "  Returns:\n",
        "  - log_mse: float, Log Mean Squared Error\n",
        "  \"\"\"\n",
        "  # Ensure inputs are numpy arrays\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "\n",
        "  # Log transformation: log(like_count + 1)\n",
        "  log_y_true = np.log1p(y_true)\n",
        "  log_y_pred = np.log1p(y_pred)\n",
        "\n",
        "  # Compute squared errors\n",
        "  squared_errors = (log_y_true - log_y_pred) ** 2\n",
        "\n",
        "  # Return the mean of squared errors\n",
        "  return np.mean(squared_errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iLc6HPPC_qAa"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def extract_post_features(post, user_avg_likes):\n",
        "    features = {}\n",
        "\n",
        "    # 1) Caption length\n",
        "    caption = post.get(\"caption\") or \"\"\n",
        "    features[\"caption_length\"] = len(caption)\n",
        "\n",
        "    # 2) Number of hashtags\n",
        "    # Count occurrences of # in caption\n",
        "    features[\"num_hashtags\"] = caption.count(\"#\")\n",
        "\n",
        "    # 3) Comments count\n",
        "    comments_count = post.get(\"comments_count\", 0) or 0\n",
        "    features[\"comments_count\"] = comments_count\n",
        "\n",
        "    # 4) Media type\n",
        "    media_type = post.get(\"media_type\", \"\").upper()\n",
        "    features[\"is_video\"] = 1 if media_type == \"VIDEO\" else 0\n",
        "    features[\"is_image\"] = 1 if media_type == \"IMAGE\" else 0\n",
        "\n",
        "    # 5) Day of week & hour of the day from timestamp\n",
        "    timestamp_str = post.get(\"timestamp\", \"\")\n",
        "    if timestamp_str:\n",
        "        dt = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
        "        features[\"day_of_week\"] = dt.weekday()  # Monday=0, Sunday=6\n",
        "        features[\"hour_of_day\"] = dt.hour\n",
        "    else:\n",
        "        features[\"day_of_week\"] = -1\n",
        "        features[\"hour_of_day\"] = -1\n",
        "\n",
        "    # 6) average likes for the user\n",
        "    features[\"user_avg_likes\"] = user_avg_likes\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "Q1k-u47X_qAb",
        "outputId": "387462fa-af4c-43b0-ad42-9931ff5704f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features shape: (89690, 8)\n",
            "Training target size: (89690,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   caption_length  num_hashtags  comments_count  is_video  is_image  \\\n",
              "0              41             0               0         0         1   \n",
              "1              76             2               1         1         0   \n",
              "2              30             1               0         1         0   \n",
              "3              58             1               1         1         0   \n",
              "4              39             2               0         1         0   \n",
              "\n",
              "   day_of_week  hour_of_day  user_avg_likes  \n",
              "0            6            9       11.848485  \n",
              "1            1           19       11.848485  \n",
              "2            0           21       11.848485  \n",
              "3            0           21       11.848485  \n",
              "4            0           21       11.848485  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9230ceea-5124-46dc-b689-c28a31ece96b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption_length</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>comments_count</th>\n",
              "      <th>is_video</th>\n",
              "      <th>is_image</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>user_avg_likes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>11.848485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>76</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>11.848485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>11.848485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>11.848485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>11.848485</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9230ceea-5124-46dc-b689-c28a31ece96b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9230ceea-5124-46dc-b689-c28a31ece96b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9230ceea-5124-46dc-b689-c28a31ece96b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b6f9450-1dad-4463-a3b4-a8ad43d09c0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b6f9450-1dad-4463-a3b4-a8ad43d09c0c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b6f9450-1dad-4463-a3b4-a8ad43d09c0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 89690,\n  \"fields\": [\n    {\n      \"column\": \"caption_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 307,\n        \"min\": 10,\n        \"max\": 2200,\n        \"num_unique_values\": 2029,\n        \"samples\": [\n          1702,\n          703,\n          989\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_hashtags\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 46,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          34,\n          40,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2331,\n        \"min\": 0,\n        \"max\": 527036,\n        \"num_unique_values\": 1897,\n        \"samples\": [\n          22249,\n          1771,\n          18114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_video\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_image\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour_of_day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          10,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_avg_likes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31299.46046935929,\n        \"min\": 0.0,\n        \"max\": 882625.1714285715,\n        \"num_unique_values\": 2535,\n        \"samples\": [\n          93.85714285714286,\n          4449.558823529412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "def compute_user_average_likes(username2posts):\n",
        "    user_avg_likes = {}\n",
        "    for username, posts in username2posts.items():\n",
        "        total_likes = 0\n",
        "        num_posts = 0\n",
        "        for post in posts:\n",
        "            like_count = post.get(\"like_count\", 0) or 0\n",
        "            total_likes += like_count\n",
        "            num_posts += 1\n",
        "        avg_likes = total_likes / num_posts if num_posts > 0 else 0\n",
        "        user_avg_likes[username] = avg_likes\n",
        "    return user_avg_likes\n",
        "\n",
        "user_train_avg_likes = compute_user_average_likes(username2posts_train)\n",
        "\n",
        "train_rows = []\n",
        "train_targets = []\n",
        "\n",
        "for uname, posts in username2posts_train.items():\n",
        "    avg_likes_for_user = user_train_avg_likes.get(uname, 0)\n",
        "\n",
        "    for post in posts:\n",
        "        features = extract_post_features(post, avg_likes_for_user)\n",
        "        true_likes = post.get(\"like_count\", 0) or 0\n",
        "\n",
        "        train_rows.append(features)\n",
        "        train_targets.append(true_likes)\n",
        "\n",
        "train_df = pd.DataFrame(train_rows)\n",
        "train_y = np.array(train_targets)\n",
        "\n",
        "print(\"Training features shape:\", train_df.shape)\n",
        "print(\"Training target size:\", train_y.shape)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gsPby4O7_qAb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df, train_y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtc-BSdi_qAb",
        "outputId": "9ac48bfd-9294-4648-febc-dc263dfa2426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 817244974.8120159\n",
            "Validation Log MSE: 0.9167332623255651\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "mse_val = mean_squared_error(y_val, y_val_pred)\n",
        "print(\"Validation MSE:\", mse_val)\n",
        "\n",
        "log_mse_val = log_mse_like_counts(y_val, y_val_pred)\n",
        "print(\"Validation Log MSE:\", log_mse_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GATq7T2F_qAb",
        "outputId": "eb271fda-3569-430d-fce2-6d83dccb797b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall average like count: 5085.267822499722\n"
          ]
        }
      ],
      "source": [
        "def calculate_overall_average_like_count(username2posts):\n",
        "    total_likes = 0\n",
        "    total_posts = 0\n",
        "    for posts in username2posts.values():\n",
        "        for post in posts:\n",
        "            like_count = post.get(\"like_count\", 0) or 0\n",
        "            total_likes += like_count\n",
        "            total_posts += 1\n",
        "    return total_likes / total_posts if total_posts > 0 else 0\n",
        "\n",
        "\n",
        "# Calculate root of the overall average like count from training data\n",
        "overall_avg_likes =  calculate_overall_average_like_count(username2posts_train)\n",
        "print(f\"Overall average like count: {overall_avg_likes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP-rZpAr_qAb",
        "outputId": "ba2faa6a-7ecd-40e0-f799-94c6ebc1b716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing test posts: 100%|██████████| 3000/3000 [00:30<00:00, 98.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output saved to /content/output_test-regression-round3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "test_file_path = \"/content/test-regression-round3.jsonl\"\n",
        "output_file_path = \"/content/output_test-regression-round3.json\"\n",
        "\n",
        "def predict_like_count_rf(model, post):\n",
        "    user_avg_likes = user_train_avg_likes.get(post.get(\"username\"), overall_avg_likes)\n",
        "    features = extract_post_features(post, user_avg_likes)\n",
        "    features_df = pd.DataFrame([features])\n",
        "    return model.predict(features_df)[0]\n",
        "\n",
        "id_like_count_map = {}\n",
        "\n",
        "with open(test_file_path, \"rt\") as test_file:\n",
        "    total_lines = sum(1 for _ in test_file)\n",
        "\n",
        "with open(test_file_path, \"rt\") as test_file:\n",
        "    for line in tqdm(test_file, total=total_lines, desc=\"Processing test posts\"):\n",
        "        sample = json.loads(line)\n",
        "        post_id = sample.get(\"id\")\n",
        "        pred_val = predict_like_count_rf(model, sample)\n",
        "\n",
        "        if post_id is not None:\n",
        "            id_like_count_map[post_id] = int(pred_val)\n",
        "\n",
        "with open(output_file_path, \"wt\") as output_file:\n",
        "    json.dump(id_like_count_map, output_file, indent=4)\n",
        "\n",
        "print(f\"Output saved to {output_file_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}